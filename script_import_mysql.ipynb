{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1858f9-0126-4754-bcd6-a9169c5d746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing business_id.csv\n",
      "NaN values before replacement:\n",
      "business_id        0\n",
      "name               0\n",
      "address          324\n",
      "city               0\n",
      "state              0\n",
      "postal_code        4\n",
      "latitude           0\n",
      "longitude          0\n",
      "stars              0\n",
      "review_count       0\n",
      "is_open            0\n",
      "attributes       441\n",
      "categories         0\n",
      "hours           3364\n",
      "dtype: int64\n",
      "\n",
      "✅ Finished inserting data into `business_id`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector \n",
    "import os\n",
    "\n",
    "# List of CSV files and their corresponding table names\n",
    "csv_files = [\n",
    "    ('business_id.csv', 'business_id')\n",
    "]\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='vansh@11singH',\n",
    "    database='demo2_msql_english'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = 'C:/Users/hp/Desktop/screenshot'\n",
    "\n",
    "# Convert pandas dtype to MySQL column type\n",
    "def get_sql_type(dtype):\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return 'INT'\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return 'FLOAT'\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return 'BOOLEAN'\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return 'DATETIME'\n",
    "    else:\n",
    "        return 'TEXT'\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file, table_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "\n",
    "        print(f\"Processing {csv_file}\")\n",
    "        print(f\"NaN values before replacement:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_') for col in df.columns]\n",
    "\n",
    "        # Create table if it doesn't exist\n",
    "        columns = ', '.join([f'`{col}` {get_sql_type(df[col].dtype)}' for col in df.columns])\n",
    "        create_table_query = f'CREATE TABLE IF NOT EXISTS `{table_name}` ({columns})'\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Prepare insert query\n",
    "        columns_str = ', '.join([f'`{col}`' for col in df.columns])\n",
    "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "        insert_query = f\"INSERT INTO `{table_name}` ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Convert dataframe rows to list of tuples\n",
    "        values = [tuple(None if pd.isna(x) else x for x in row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "        # Batch insert\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(values), batch_size):\n",
    "            batch = values[i:i + batch_size]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"✅ Finished inserting data into `{table_name}`\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {csv_file}: {e}\\n\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df803718-9fe4-451b-85b9-cb947c487081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing checkin.csv\n",
      "NaN values before replacement:\n",
      "Column1    0\n",
      "Column2    0\n",
      "dtype: int64\n",
      "\n",
      "✅ Finished inserting data into `checkin`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector \n",
    "import os\n",
    "\n",
    "csv_files = [\n",
    "    ('checkin.csv', 'checkin')\n",
    "]\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='vansh@11singH',\n",
    "    database='demo2_msql_english'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = 'C:/Users/hp/Desktop/screenshot'\n",
    "\n",
    "# Convert pandas dtype to MySQL column type\n",
    "def get_sql_type(col, dtype):\n",
    "    # Special handling for checkin_date column (can contain very long strings)\n",
    "    if col.lower() in [\"date\", \"checkin_date\"]:\n",
    "        return \"LONGTEXT\"\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INT\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"FLOAT\"\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return \"BOOLEAN\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return \"DATETIME\"\n",
    "    else:\n",
    "        return \"LONGTEXT\"  # default to LONGTEXT for safety\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file, table_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "\n",
    "        print(f\"Processing {csv_file}\")\n",
    "        print(f\"NaN values before replacement:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_') for col in df.columns]\n",
    "\n",
    "        # Rename BEFORE creating schema\n",
    "        if 'date' in df.columns:\n",
    "            df.rename(columns={'date': 'checkin_date'}, inplace=True)\n",
    "\n",
    "        # ✅ Now MySQL table & insert will use \"checkin_date\"\n",
    "        columns = ', '.join([f'`{col}` {get_sql_type(col, df[col].dtype)}' for col in df.columns])\n",
    "        create_table_query = f'CREATE TABLE IF NOT EXISTS `{table_name}` ({columns})'\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS `{table_name}`\")  # drop old wrong table\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Prepare insert query\n",
    "        columns_str = ', '.join([f'`{col}`' for col in df.columns])\n",
    "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "        insert_query = f\"INSERT INTO `{table_name}` ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Convert dataframe rows to list of tuples\n",
    "        values = [tuple(None if pd.isna(x) else x for x in row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "        # Batch insert\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(values), batch_size):\n",
    "            batch = values[i:i + batch_size]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"✅ Finished inserting data into `{table_name}`\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {csv_file}: {e}\\n\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b014082d-ee3e-49ab-b683-f6d4b6503fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tip.csv\n",
      "NaN values before replacement:\n",
      "user_id             0\n",
      "business_id         0\n",
      "text                7\n",
      "date                0\n",
      "compliment_count    0\n",
      "dtype: int64\n",
      "\n",
      "✅ Finished inserting data into `tip`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector \n",
    "import os\n",
    "\n",
    "csv_files = [\n",
    "    ('tip.csv', 'tip')\n",
    "]\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='vansh@11singH',\n",
    "    database='demo2_msql_english'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = 'C:/Users/hp/Desktop/screenshot'\n",
    "\n",
    "# Convert pandas dtype to MySQL column type\n",
    "def get_sql_type(col, dtype):\n",
    "    # Special handling for checkin_date column (can contain very long strings)\n",
    "    if col.lower() in [\"date\", \"checkin_date\"]:\n",
    "        return \"LONGTEXT\"\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INT\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"FLOAT\"\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return \"BOOLEAN\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return \"DATETIME\"\n",
    "    else:\n",
    "        return \"LONGTEXT\"  # default to LONGTEXT for safety\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file, table_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "\n",
    "        print(f\"Processing {csv_file}\")\n",
    "        print(f\"NaN values before replacement:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_') for col in df.columns]\n",
    "\n",
    "        # Rename BEFORE creating schema\n",
    "        if 'date' in df.columns:\n",
    "            df.rename(columns={'date': 'checkin_date'}, inplace=True)\n",
    "\n",
    "        # ✅ Now MySQL table & insert will use \"checkin_date\"\n",
    "        columns = ', '.join([f'`{col}` {get_sql_type(col, df[col].dtype)}' for col in df.columns])\n",
    "        create_table_query = f'CREATE TABLE IF NOT EXISTS `{table_name}` ({columns})'\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS `{table_name}`\")  # drop old wrong table\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Prepare insert query\n",
    "        columns_str = ', '.join([f'`{col}`' for col in df.columns])\n",
    "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "        insert_query = f\"INSERT INTO `{table_name}` ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Convert dataframe rows to list of tuples\n",
    "        values = [tuple(None if pd.isna(x) else x for x in row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "        # Batch insert\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(values), batch_size):\n",
    "            batch = values[i:i + batch_size]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"✅ Finished inserting data into `{table_name}`\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {csv_file}: {e}\\n\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cb70a9-2812-4f91-a170-23c3d2b7f21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing new_checkin.csv\n",
      "NaN values before replacement:\n",
      "business_id    0\n",
      "date           0\n",
      "dtype: int64\n",
      "\n",
      "✅ Finished inserting data into `new_checkin`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector \n",
    "import os\n",
    "\n",
    "csv_files = [\n",
    "    ('new_checkin.csv', 'new_checkin')\n",
    "]\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='vansh@11singH',\n",
    "    database='demo2_msql_english'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = 'C:/Users/hp/Desktop/screenshot'\n",
    "\n",
    "# Convert pandas dtype to MySQL column type\n",
    "def get_sql_type(col, dtype):\n",
    "    # Special handling for checkin_date column (can contain very long strings)\n",
    "    if col.lower() in [\"date\", \"checkin_date\"]:\n",
    "        return \"LONGTEXT\"\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INT\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"FLOAT\"\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return \"BOOLEAN\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return \"DATETIME\"\n",
    "    else:\n",
    "        return \"LONGTEXT\"  # default to LONGTEXT for safety\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file, table_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "\n",
    "        print(f\"Processing {csv_file}\")\n",
    "        print(f\"NaN values before replacement:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_') for col in df.columns]\n",
    "\n",
    "        # Rename BEFORE creating schema\n",
    "        if 'date' in df.columns:\n",
    "            df.rename(columns={'date': 'checkin_date'}, inplace=True)\n",
    "\n",
    "        # ✅ Now MySQL table & insert will use \"checkin_date\"\n",
    "        columns = ', '.join([f'`{col}` {get_sql_type(col, df[col].dtype)}' for col in df.columns])\n",
    "        create_table_query = f'CREATE TABLE IF NOT EXISTS `{table_name}` ({columns})'\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS `{table_name}`\")  # drop old wrong table\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Prepare insert query\n",
    "        columns_str = ', '.join([f'`{col}`' for col in df.columns])\n",
    "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "        insert_query = f\"INSERT INTO `{table_name}` ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Convert dataframe rows to list of tuples\n",
    "        values = [tuple(None if pd.isna(x) else x for x in row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "        # Batch insert\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(values), batch_size):\n",
    "            batch = values[i:i + batch_size]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"✅ Finished inserting data into `{table_name}`\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {csv_file}: {e}\\n\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86df5b2-330a-4f8b-a562-9f90a644e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing reviews.csv\n",
      "NaN values before replacement:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n",
      "\n",
      "✅ Finished inserting data into `reviews`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector \n",
    "import os\n",
    "\n",
    "csv_files = [\n",
    "    ('reviews.csv', 'reviews')\n",
    "]\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='vansh@11singH',\n",
    "    database='demo2_msql_english'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = 'C:/Users/hp/Desktop/screenshot'\n",
    "\n",
    "# Convert pandas dtype to MySQL column type\n",
    "def get_sql_type(col, dtype):\n",
    "    # Special handling for checkin_date column (can contain very long strings)\n",
    "    if col.lower() in [\"date\", \"checkin_date\"]:\n",
    "        return \"LONGTEXT\"\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INT\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"FLOAT\"\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return \"BOOLEAN\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return \"DATETIME\"\n",
    "    else:\n",
    "        return \"LONGTEXT\"  # default to LONGTEXT for safety\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file, table_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "\n",
    "        print(f\"Processing {csv_file}\")\n",
    "        print(f\"NaN values before replacement:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_') for col in df.columns]\n",
    "\n",
    "        # Rename BEFORE creating schema\n",
    "        if 'date' in df.columns:\n",
    "            df.rename(columns={'date': 'checkin_date'}, inplace=True)\n",
    "\n",
    "        # ✅ Now MySQL table & insert will use \"checkin_date\"\n",
    "        columns = ', '.join([f'`{col}` {get_sql_type(col, df[col].dtype)}' for col in df.columns])\n",
    "        create_table_query = f'CREATE TABLE IF NOT EXISTS `{table_name}` ({columns})'\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS `{table_name}`\")  # drop old wrong table\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Prepare insert query\n",
    "        columns_str = ', '.join([f'`{col}`' for col in df.columns])\n",
    "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "        insert_query = f\"INSERT INTO `{table_name}` ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Convert dataframe rows to list of tuples\n",
    "        values = [tuple(None if pd.isna(x) else x for x in row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "        # Batch insert\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(values), batch_size):\n",
    "            batch = values[i:i + batch_size]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"✅ Finished inserting data into `{table_name}`\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {csv_file}: {e}\\n\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb90a89-d4f6-42c5-8607-900624e3aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10684\\1818286120.py:42: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user.csv\n",
      "NaN values before replacement:\n",
      "user_id                     0\n",
      "name                       37\n",
      "review_count                0\n",
      "yelping_since               0\n",
      "useful                      0\n",
      "funny                       0\n",
      "cool                        0\n",
      "elite                 1896699\n",
      "friends                878551\n",
      "fans                        0\n",
      "average_stars               0\n",
      "compliment_hot              0\n",
      "compliment_more             0\n",
      "compliment_profile          0\n",
      "compliment_cute             0\n",
      "compliment_list             0\n",
      "compliment_note             0\n",
      "compliment_plain            0\n",
      "compliment_cool             0\n",
      "compliment_funny            0\n",
      "compliment_writer           0\n",
      "compliment_photos           0\n",
      "dtype: int64\n",
      "\n",
      "✅ Finished inserting data into `user`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector \n",
    "import os\n",
    "\n",
    "csv_files = [\n",
    "    ('user.csv', 'user')\n",
    "]\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='vansh@11singH',\n",
    "    database='demo2_msql_english'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = 'C:/Users/hp/Desktop/screenshot'\n",
    "\n",
    "# Convert pandas dtype to MySQL column type\n",
    "def get_sql_type(col, dtype):\n",
    "    # Special handling for checkin_date column (can contain very long strings)\n",
    "    if col.lower() in [\"date\", \"checkin_date\"]:\n",
    "        return \"LONGTEXT\"\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"INT\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"FLOAT\"\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return \"BOOLEAN\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return \"DATETIME\"\n",
    "    else:\n",
    "        return \"LONGTEXT\"  # default to LONGTEXT for safety\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file, table_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "\n",
    "        print(f\"Processing {csv_file}\")\n",
    "        print(f\"NaN values before replacement:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_') for col in df.columns]\n",
    "\n",
    "        # Rename BEFORE creating schema\n",
    "        if 'date' in df.columns:\n",
    "            df.rename(columns={'date': 'checkin_date'}, inplace=True)\n",
    "\n",
    "        # ✅ Now MySQL table & insert will use \"checkin_date\"\n",
    "        columns = ', '.join([f'`{col}` {get_sql_type(col, df[col].dtype)}' for col in df.columns])\n",
    "        create_table_query = f'CREATE TABLE IF NOT EXISTS `{table_name}` ({columns})'\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS `{table_name}`\")  # drop old wrong table\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Prepare insert query\n",
    "        columns_str = ', '.join([f'`{col}`' for col in df.columns])\n",
    "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "        insert_query = f\"INSERT INTO `{table_name}` ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Convert dataframe rows to list of tuples\n",
    "        values = [tuple(None if pd.isna(x) else x for x in row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "        # Batch insert\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(values), batch_size):\n",
    "            batch = values[i:i + batch_size]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"✅ Finished inserting data into `{table_name}`\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {csv_file}: {e}\\n\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
